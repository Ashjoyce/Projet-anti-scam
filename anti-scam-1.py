                                                                            # L'ex√©cution dans le terminal

from huggingface_hub import InferenceClient
from google.cloud import texttospeech, speech
import os
import sounddevice as sd
import soundfile as sf
import logging
import random

# --- Configuration ---

# Hugging Face LLM client
llm_client = InferenceClient(
    provider="hf-inference",
    api_key="eyJhbGciOiJIUzI1NiIsImtpZCI6IlV6SXJWd1h0dnprLVRvdzlLZWstc0M1akptWXBvX1VaVkxUZlpnMDRlOFUiLCJ0eXAiOiJKV1QifQ.eyJzdWIiOiJnb29nbGUtb2F1dGgyfDExNTYyMDQwMjcwMTg4NDk2NDk1MSIsInNjb3BlIjoib3BlbmlkIG9mZmxpbmVfYWNjZXNzIiwiaXNzIjoiYXBpX2tleV9pc3N1ZXIiLCJhdWQiOlsiaHR0cHM6Ly9uZWJpdXMtaW5mZXJlbmNlLmV1LmF1dGgwLmNvbS9hcGkvdjIvIl0sImV4cCI6MTkwMjQ3NTYwMCwidXVpZCI6Ijg2MzExNjIyLTJjMjQtNDdlYS04ZmI2LTJhOGUzOGUzYmM4MCIsIm5hbWUiOiJlc3RpYW0iLCJleHBpcmVzX2F0IjoiMjAzMC0wNC0xNVQwOToyNjo0MCswMDAwIn0.tuplcuYfIAIlXm_aoqv9sY56XQ41HS6wfxliVe5tlck",
) # il faut remplacer l'API

# Authentification Google Cloud
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "key.json"

# Logger pour enregistrer les conversations
logging.basicConfig(
    filename="logs/conversation.log",
    level=logging.INFO,
    format="%(asctime)s - USER: %(message)s"
)

# --- Contexte conversationnel ---

context = "Tu es une fausse victime d'arnaque. Tu sers √† faire perdre du temps √† un arnaqueur."
personnalite = "Tu es un homme de 45 ans, Michel CASPER, na√Øf et tr√®s cr√©dule."
instructions = (
    "Tu dois poser des questions √† l'escroc, t'embrouiller parfois, et faire durer l'appel."
    " Sois gentil, lent √† comprendre, mais curieux. Ne r√©v√®le jamais que tu es une IA."
)

messages = [{
    "role": "system",
    "content": f"{context}\n{personnalite}\n{instructions}"
}]

# --- Fonctions principales ---

def record_audio(duration=5, sample_rate=44100):
    print("üéô Enregistrement...")
    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')
    sd.wait()
    print("‚úÖ Enregistrement termin√©.")
    sf.write("voice.flac", audio_data, sample_rate)

def transcribe_audio():
    speech_client = speech.SpeechClient()
    with open("voice.flac", "rb") as audio_file:
        content = audio_file.read()
    audio = speech.RecognitionAudio(content=content)
    config = speech.RecognitionConfig(sample_rate_hertz=44100, language_code="fr-FR")

    speech_result = speech_client.recognize(config=config, audio=audio)

    if not speech_result.results:
        print("‚ö†Ô∏è Aucune voix d√©tect√©e.")
        return ""
    transcript = speech_result.results[0].alternatives[0].transcript
    logging.info(f"ARNAQUEUR: {transcript}")
    return transcript

def generate_response(user_input):
    messages.append({"role": "user", "content": user_input})
    
    try:
        completion = llm_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=200,
            temperature=0.9
        )
        response = completion.choices[0].message.content.strip()
        
        # --- Variabilit√© des r√©ponses ---
        
        # Exemple de randomisation de la longueur de la r√©ponse
        response_variations = [
            f"{response} En tout cas, c'est vraiment √©trange... Hmm, je ne comprends pas.",
            f"Ah oui, c'est bizarre ce que tu dis l√†. Je vais devoir r√©fl√©chir. {response}",
            f"Je vois... C'est vraiment √©trange. Peut-√™tre que tu peux m'expliquer encore une fois ce que tu veux dire ? {response}",
            f"Je ne sais pas si je te comprends bien... Tu peux r√©p√©ter √ßa plus lentement ? {response}",
            f"Hum, tu veux dire que... Oh je ne suis pas s√ªr... mais {response}."
        ]
        
        # Randomisation dans les r√©ponses pour √©viter la r√©p√©tition
        response = random.choice(response_variations)

    except Exception as e:
        print(f"Erreur LLM : {e}")
        response = "Euh... je ne suis pas s√ªr de comprendre..."
        
    messages.append({"role": "assistant", "content": response})
    logging.info(f"MICHEL: {response}")
    return response

def speak_text(text):
    tts_client = texttospeech.TextToSpeechClient()

    # Construction SSML avec h√©sitations et pauses
    ssml_text = f"""
    <speak>
        <prosody rate="medium" pitch="medium">
            Hmm... <break time="600ms"/> {text.replace(",", "<break time='400ms'/>").replace(".", "<break time='600ms'/>")}
        </prosody>
    </speak>
    """

    synthesis_input = texttospeech.SynthesisInput(ssml=ssml_text)
    voice = texttospeech.VoiceSelectionParams(
        language_code='fr-FR',
        name='fr-FR-Neural2-D',
        ssml_gender=texttospeech.SsmlVoiceGender.MALE
    )
    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)

    response = tts_client.synthesize_speech(
        input=synthesis_input,
        voice=voice,
        audio_config=audio_config
    )

    with open('output.mp3', 'wb') as out:
        out.write(response.audio_content)

    print("üîä Audio g√©n√©r√© avec intonations et pauses.")

# --- Boucle principale ---

if not os.path.exists("logs"):
    os.makedirs("logs")

print("üí¨ Lancement du pi√®ge vocal... Appuyez sur Ctrl+C pour quitter.")

try:
    while True:
        record_audio()
        user_input = transcribe_audio()
        if user_input:
            print("üë§ Arnaqueur :", user_input)
            reply = generate_response(user_input)
            print("ü§ñ Michel :", reply)
            speak_text(reply)
        else:
            print("üòê Silence d√©tect√©.")
except KeyboardInterrupt:
    print("\nüõë Conversation termin√©e.")
